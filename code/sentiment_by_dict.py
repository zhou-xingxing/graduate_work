# -*- coding: utf-8 -*-
"""
Created on Tue Mar 31 18:46:50 2020

@author: lenovo
"""

#åŸºäºè¯å…¸çš„æƒ…æ„Ÿåˆ†æ
import jieba
import os,time,csv
from pyltp import Segmentor
from data_cleaning import *
from langconv import *
import pandas as pd


# åŠ è½½è‡ªå®šä¹‰è¯å…¸
jieba.load_userdict(r'../dict/self_dict.txt')


LTP_DATA_DIR = r'../ltp_data_v3.4.0/ltp_data_v3.4.0'  # ltpæ¨¡å‹ç›®å½•çš„è·¯å¾„
cws_model_path = os.path.join(LTP_DATA_DIR, 'cws.model')  # åˆ†è¯æ¨¡å‹è·¯å¾„ï¼Œæ¨¡å‹åç§°ä¸º`cws.model`
segmentor = Segmentor()  # åˆå§‹åŒ–å®ä¾‹
segmentor.load_with_lexicon(cws_model_path, r"../dict/self_dict.txt")  # åŠ è½½æ¨¡å‹ï¼Œç¬¬äºŒä¸ªå‚æ•°æ˜¯æ‚¨çš„å¤–éƒ¨è¯å…¸æ–‡ä»¶è·¯å¾„

pos_dict=pd.read_csv(r'../dict/self_positive_dict.txt',header=None)
pos_dict=pos_dict[0].tolist()

neg_dict=pd.read_csv(r'../dict/self_negative_dict.txt',header=None)
neg_dict=neg_dict[0].tolist()

not_dict=pd.read_csv(r'../dict/self_not.txt',header=None)
not_dict=not_dict[0].tolist()

with open("../dict/self_degree.txt",'r',encoding='utf-8') as f:    
    degree=eval(f.read()) #æŠŠå­—å…¸è½¬åŒ–ä¸ºstr 

degree_most=degree['most']
degree_more=degree['more']
degree_less=degree['less']
degree_least=degree['least']

print('æ­£é¢æƒ…æ„Ÿè¯:',len(pos_dict))
print('è´Ÿé¢æƒ…æ„Ÿè¯:',len(neg_dict))
print('å¦å®šè¯:',len(not_dict))
print('ç¨‹åº¦å‰¯è¯:',len(degree_most),len(degree_more),len(degree_less),len(degree_least))

#æ•°æ®æ¸…æ´—
def danmu_clean(sentence):
    with open(r"../dict/dyemot.txt", 'r')as f:
        emot_dict = eval(f.read())
        
    sentence=symbol_replace(sentence)
    sentence=tradition2simple(sentence)
    sentence=sim_replace(sentence)
    sentence=emoji_replace(sentence)
    
    return sentence


#jiebaåˆ†è¯
def jieba_word(sentence):
    seg_list = jieba.cut(sentence)
    seg_result = []
# å»å¤šä½™ç©ºæ ¼
    for i in seg_list:
        if i==' ':
            continue
        else:
            seg_result.append(i)
    
    return seg_result

#ltpåˆ†è¯
def ltp_word(sentence):
    seg_result = segmentor.segment(sentence)
    return list(seg_result)


#è®¡ç®—æƒ…æ„Ÿå¾—åˆ†    
def sentence_score(seg_result):
    pos_score=0
    neg_score=0
    
    for i in range(0,len(seg_result)):        
        if seg_result[i] in pos_dict:
            print('pos:',seg_result[i])
            tmp=1
#            å‘å‰æŸ¥1-2ä¸ªè¯
            for j in [1,2]:
                if i-j<0:
                    break
#                æœ‰æ ‡ç‚¹è¯´æ˜å‰åæ— è”ç³»ï¼Œæå‰ç»“æŸ
                if seg_result[i-j]==',' or seg_result[i-j]=='.':
                    break
                else:
                    if seg_result[i-j] in not_dict:
                        tmp=tmp*-1
                        continue
                    elif seg_result[i-j] in degree_most:
                        tmp=tmp*1.75
                        continue
                    elif seg_result[i-j] in degree_more:
                        tmp=tmp*1.5
                        continue
                    elif seg_result[i-j] in degree_less:
                        tmp=tmp*0.75
                        continue
                    elif seg_result[i-j] in degree_least:
                        tmp=tmp*0.5
                        continue
            pos_score+=tmp
        elif seg_result[i] in neg_dict:
            print('neg:',seg_result[i])
            tmp=1
#            å‘å‰æŸ¥1-2ä¸ªè¯
            for j in [1,2]:
                if i-j<0:
                    break
                if seg_result[i-j]==',' or seg_result[i-j]=='.':
                    break
                else:
                    if seg_result[i-j] in not_dict:
#                        è´Ÿé¢è¯è¢«å¦å®šè¯ä¿®é¥°è§†ä¸ºæ— æƒ…æ„Ÿæˆ–ç•¥å¾®æ­£å‘
                        tmp=tmp*0
                        continue
                    elif seg_result[i-j] in degree_most:
                        tmp=tmp*1.75
                        continue
                    elif seg_result[i-j] in degree_more:
                        tmp=tmp*1.5
                        continue
                    elif seg_result[i-j] in degree_less:
                        tmp=tmp*0.75
                        continue
                    elif seg_result[i-j] in degree_least:
                        tmp=tmp*0.5
                        continue
            neg_score+=tmp
    
    score=pos_score-neg_score
#    print('score',score)
#    å¦‚æœå¥å­æœ€åæœ‰å¹å·
    if  seg_result[-1]=='!':
        score*=1.5
    return score    
                           
                        
#è¾“å‡ºå•æ¡å¼¹å¹•æƒ…æ„Ÿåˆ†æç»“æœ                        
def sentiment_result(sentence):                

#    åªæœ‰åœ¨æµ‹è¯•å•æ¡å¼¹å¹•æ—¶æ‰éœ€è¦æ¸…æ´—
#    sentence=danmu_clean(sentence)
#    ç‰¹æ®Šå¤„ç†ä¸¤ç§æƒ…å†µ
    if sentence=='???':
#        print('è´Ÿé¢')
        jieba_res=-1
        ltp_res=-1
#        return (jieba_res,ltp_res)  
        return jieba_res
    if sentence=='!!!':
#        print('æ­£é¢')
        jieba_res=1
        ltp_res=1
#        return (jieba_res,ltp_res)  
        return jieba_res
    if len(sentence)==0 or sentence==',' or sentence=='.':
#        print('ä¸­æ€§')
        jieba_res=0
        ltp_res=0
#        return (jieba_res,ltp_res) 
        return jieba_res
    
    
    jieba_list=jieba_word(sentence)
#    ltp_list=ltp_word(sentence)
#    
    print('jieba_list:',jieba_list)
#    print('ltp_list:',ltp_list)
#    
    sentiment_jieba=sentence_score(jieba_list)
#    sentiment_ltp=sentence_score(ltp_list)
    
#    if sentiment_jieba>0:
#        print('jieba:','socre',sentiment_jieba,'class','æ­£é¢')
#    elif sentiment_jieba<0:
#        print('jieba:','socre',sentiment_jieba,'class','è´Ÿé¢')
#    else:
#        print('jieba:','socre',sentiment_jieba,'class','ä¸­æ€§')
#        
#    if sentiment_ltp>0:
#        print('ltp:','socre',sentiment_ltp,'class','æ­£é¢')
#    elif sentiment_ltp<0:
#        print('ltp:','socre',sentiment_ltp,'class','è´Ÿé¢')
#    else:
#        print('ltp:','socre',sentiment_ltp,'class','ä¸­æ€§')    
#    
#    if sentiment_jieba>0:
#        jieba_res=1
#    elif sentiment_jieba<0:
#        jieba_res=-1
#    else:
#        jieba_res=0
#        
#    if sentiment_ltp>0:
#        ltp_res=1
#    elif sentiment_ltp<0:
#        ltp_res=-1
#    else:
#        ltp_res=0
    
#    return (jieba_res,ltp_res)    
    return sentiment_jieba

#æŒ‰æ—¶é—´æ®µåˆ¤æ–­æƒ…æ„Ÿ
def sentiment_fragment(danmu_list):
    sentiment_score_list=[]
    sentiment_pos_score=[]
    sentiment_neg_score=[]
    for i in danmu_list:
        score=sentiment_result(i)
        sentiment_score_list.append(score)
        if score>0:
            sentiment_pos_score.append(score)
        if score<0:
            sentiment_neg_score.append(score)
    num=len(sentiment_score_list)        
    avg=sum(sentiment_score_list)/num
#è¿”å›æƒ…æ„Ÿå€¼ç´¯ç§¯å’Œã€å¹³å‡å€¼ã€æ­£å‘å’Œã€è´Ÿå‘å’Œ
#    return (sum(sentiment_score_list),avg,sum(sentiment_pos_score),sum(sentiment_neg_score))
#è¿”å›æƒ…æ„Ÿå‡å€¼ã€æ­£é¢æƒ…æ„Ÿå‡å€¼ã€æ­£é¢å¼¹å¹•æ¯”ã€è´Ÿé¢æƒ…æ„Ÿå‡å€¼ã€è´Ÿé¢å¼¹å¹•æ¯”
    return  (avg,sum(sentiment_pos_score)/num,len(sentiment_pos_score)/num,sum(sentiment_neg_score)/num,len(sentiment_neg_score)/num)  



#â¤ï¸
#â¤ è¿™ä¸¤ç§çº¢å¿ƒä¸ä¸€æ ·   
sentence="åˆ«å–·äº† æç¬‘ æœ‰ç‚¹é“ç† æœ‰ç‚¹ç‰› è¿™ä»–å¦ˆæ‰“çš„ä»€ä¹ˆ æœ‰ç‚¹æ°´ æ°´å‹ æ”¾æ°´ æˆ‘æƒ³å–æ°´"
i=sentiment_result(sentence)
print(i)
#    
#æµ‹è¯•å¼¹å¹•
def test_danmu():    
    test_data=pd.read_csv(r'../data/test300_result_verify.csv')
    print('æµ‹è¯•æ•°é‡ï¼š',len(test_data))
    jieba_flag=[]
    ltp_flag=[]
    start_time=time.clock()
    for index,row in test_data.iterrows():
        danmu=str(row['danmu'])
        jieba_res,ltp_res=sentiment_result(danmu)
    #    print(jieba_res,ltp_res)
        jieba_flag.append(jieba_res)
        ltp_flag.append(ltp_res)
    end_time=time.clock()
    print('æµ‹è¯•ç”¨æ—¶ï¼š',end_time-start_time)
    test_data['jieba']=jieba_flag
    test_data['ltp']=ltp_flag
    test_data.to_csv(r'../data/test300_result_verify.csv',index=None)
#
#æµ‹è¯•æ—¶é—´æ®µå¼¹å¹•
def test_danmu_frag():
#    è¿è¡Œ36ç§’
    data=pd.read_csv(r'../code/frag_cleaned_test_room911_20000.csv')
    time_group=data.groupby('fragment')    
    time_frag=[]
#    score_frag=[]
    avg_frag=[]
    pos_avg_frag=[]
    pos_pro_frag=[]
#    pos_frag=[]
#    neg_frag=[]
    start_time=time.clock()
    for gn,gl in time_group:
#        ä»¥æ¯ç»„ç¬¬ä¸€æ¡å¼¹å¹•æ—¶é—´ä¸ºåæ ‡å€¼
        time_frag.append(gl['time'].tolist()[0])
        avg,pos_avg,pos_pro=sentiment_fragment(gl['content'].tolist())
        
        avg_frag.append(avg)
        pos_avg_frag.append(pos_avg)
        pos_pro_frag.append(pos_pro)
    end_time=time.clock()
    print('æµ‹è¯•ç”¨æ—¶ï¼š',end_time-start_time)
    dic={'time_frag':time_frag,'avg_score':avg_frag,'pos_avg':pos_avg_frag,'pos_proportion':pos_pro_frag}
    senti_frag=pd.DataFrame(dic)
    senti_frag.to_csv(r'../code/new2_senti_frag_cleaned_test_room911_20000.csv',index=None)

#test_danmu_frag()

#ä¸ºæ—¶é—´æ®µåŠ ç‰¹å¾
def feature_danmu_frag():
#    180s
    data=pd.read_csv(r'../data/room36252/new_flagfeature_final_room36252danmu0318.csv') 
    avg_ls=[]
    pos_avg_ls=[]
    pos_prop_ls=[]
    neg_avg_ls=[]
    neg_prop_ls=[]
    start_time=time.clock()
    for index,row in data.iterrows():
#        print(row['danmu'],type(row['danmu']))
        avg,pos_avg,pos_prop,neg_avg,neg_prop=sentiment_fragment(eval(row['danmu']))
        
        avg_ls.append(avg)
        pos_avg_ls.append(pos_avg)
        pos_prop_ls.append(pos_prop)
        neg_avg_ls.append(neg_avg)
        neg_prop_ls.append(neg_prop)
    
    end_time=time.clock()
    print('æµ‹è¯•ç”¨æ—¶ï¼š',end_time-start_time)
    data['avg_score']=avg_ls
    data['pos_avg_score']=pos_avg_ls
    data['pos_proportion']=pos_prop_ls
    data['neg_avg_score']=neg_avg_ls
    data['neg_proportion']=neg_prop_ls
    
    data.to_csv(r'../data/room36252/new_flagfeature_final_room36252danmu0318.csv',index=None)
    
    
    
        
#feature_danmu_frag()

#test_list=['æœ‰é“ç†å‘€', 'è®¸è¯ºä»Šå¤©æœ‰ç‚¹ä¸‹é¥­', 'æˆ‘å»', 'ag 3:0 qgä¸è§£é‡Š', 'å¼ é£ä¸€ç‚¹æ„è¯†æ²¡æœ‰  æ—©å¤§å°±å¯ä»¥äº†', 'ç”¨è–ªåˆ›é€ å¿«ä¹.', 'å¼ é£è‚¯å®šä»¥ä¸ºå¯ä»¥ç›´æ¥æ€å•Š', 'æˆ‘è§‰å¾—770å¼€å›¢è¾…åŠ©ç©çš„ä¸å¥½,ä½†æ˜¯å¼ é£ç©çš„æ¯”è¿™ä¸ªç»å¯¹å¼ºä¸€ç‚¹å§', 'ä¸æƒ³å–·,è¾…åŠ©è¿˜æ˜¯æœ‰é—®é¢˜', 'agå†²å†²å†²', 'æ‰“é‡å§,è®©buff', 'qgä¹°äº†æœ€åˆ?', 'æˆ‘è¦å¾—ä¸€å„¿', 'é»‘æš´å¿«å“­äº†', 'qgè¾…åŠ©æ²¡ä¸€ä¸ªå¥½çš„', 'å¯ä»¥å¯ä»¥', 'å¼ é£å¤§ç‹‚é“é—ªæ¢äº†ä¸€ä¸ªé»„å¿ é—ª', 'ä¸ºä»€ä¹ˆä¹åˆ†é’Ÿå°±æœ‰å°é¾™', 'æ²¡æœ‰å¤§æ‹›çš„å¼ é£æ²¡åŠæ³•æŠ¢é¾™ æ‰€ä»¥æƒ³ç•™', 'è°èƒ½æƒ³åˆ°å•Š?', 'qg åŠ æ²¹', 'å–·è®¸è¯ºçš„äº‹é¡¹ä¸Šä¹æœˆå—?', 'å¤ªä¹™æ„è¯†å¾ˆå¥½ä¹Ÿ', 'å¸¦èŠ‚å¥çš„å‡ºå»,æ²¡äººå«ä½ çœ‹', 'é©¬å…‹ç»æµå¤š', 'å“”å“”è¾…åŠ©å¹²å˜›', 'ä½ åˆ°åº•æ˜¯é‚£è¾¹çš„', 'è½»ç‚¹å–·,ä½ ä»¬qgè¾…åŠ©å°‘,å–·èµ°äº†å°±æ²¡äº†', 'è®¸è¯ºä»¥ä¸ºflyèƒ½æ€æ²¡é—®é¢˜å•Šå•Šå•Š', 'è¿™ä¸ªä¸æŠ¢äººå¤´å¥½ä¸å¥½', 'ç©è¿‡è¾…åŠ©?åœ¨è¿™æ¯”æ¯”?', 'å“‡', 'åˆºç—›äº‰ç‚¹æ°”å•Š', 'åç€ä¹°,åˆ«å¢…é æµ·', 'ä¸Šå¸è§†é‡ç‰›é€¼?', 'ä¸€åŠ¨ä¸åŠ¨ä¼¼ç‹å…«', '233', 'è®¸è¯ºå°±æ˜¯snow', 'å“ˆå“ˆå“ˆå•Šå“ˆå“ˆå“ˆ', 'ä¸€åŠ¨ä¸åŠ¨ä¼¼ç‹å…«', 'èµ«å°”ç‰¹çš„ç”µçº¿æ†æ˜¯ä½ æ’çš„å§', 'æˆ‘åˆšæ‰ä¹Ÿä»¥ä¸ºç‹‚é“èƒ½æ€å•Š,ä¸ºä»€ä¹ˆè¦æ”¾å¤§', 'åˆºç—›å®¶æ²¡æœ‰ç½‘', 'å“ˆå“ˆå“ˆ', 'å¸¦èŠ‚å¥å…³ä½ åŠäº‹,è‡ªå·±å±è”½å¼¹å¹•', 'é©¬å¯ç»æµå¥½é«˜', 'å¤ªéš¾äº†å¤ªéš¾äº†', 'å¼€ä¸ªå¼±åŒ–è¿›å»å°±èƒ½é¡¶ä½', 'qgç‹—æ€¥äº†?', 'äººå®¶æ„¿æ„è¯´,æ²¡åŠæ³• @awyj86985ï¼šè®¸è¯ºæ€ä¹ˆäº†,å–·å­æœ‰ç—…å§', 'ä¸è¦å¸¦èŠ‚å¥', 'å”‰', 'è¿™æŠŠæ„Ÿè§‰qgè¦æ— äº†...', 'åˆ«å¸¦è®¸è¯ºèŠ‚å¥.!', 'æ²¡è§†é‡å•Š', 'è¿˜ä»¥ä¸ºæ›œé©¯é¾™é«˜æ‰‹', 'æ‰€ä»¥ä¸ºä»€ä¹ˆä¸ä¹°æœ€åˆå•Š?', 'æœ«å°†æŒ‰çš„å¥½', 'è¿˜æ˜¯flyå‘€', 'æ€»æ˜¯æœ‰äº›å–·å­å–œæ¬¢ä¹±å–· äººåœ¨æ¯ä¸€ä¸ªä¸»æ’­çš„ç›´æ’­é—´é‡Œéƒ½ä¼šè§åˆ°', 'ä¸€ä¸ªè¾¹è·¯å·²ç»ä¸é”™äº†', 'å“ˆå“ˆå“ˆ', 'æœ€åˆæ˜¯ç»æµåˆå®æƒ ', 'åˆæ— äº†', 'å“ˆå“ˆå“ˆ', 'é‚£å°±æ˜¯flyçš„é—®é¢˜å‘—', 'é»„å¿ èµ·æ¥äº†è¦æ€ä¹ˆæ‰“', 'æˆ‘æ˜¯çœŸçš„ä¸æ‡‚ä½ ä»¬å½“åˆä¸ºä»€ä¹ˆä¸ä¹°æœ€åˆ', 'qgæ‰“å¾—çœŸæ°”äººå•Š', 'æœ‰å†…é¬¼', 'qgè°åœ¨æŒ‡æŒ¥?', 'qg', 'ç„¶åå°±è¢«å¼€äº†', 'æœ‰é“ç†å‘€', 'ä½ çœŸçš„ç§€', 'æ— äº†å•Š', 'ä¸€åŠ¨ä¸åŠ¨æ˜¯ç‹å…«', 'giaoä¹‹å‰åœ¨ç»ƒæç™½', 'æˆ‘è¦å¾—ä¸€å„¿', 'å“‡', 'åˆ«éª‚å¼ é£ è®¸è¯ºæ¯”éŸ­é»„å¥½å¤ªå¤šäº†', 'ä½ é‚£è¾¹çš„?', 'æ¯’å¥¶', '...', 'æ€ä¹ˆæ‰“æˆè¿™æ ·äº†', 'ç¬¬äºŒæ‰“é‡', 'æ— äº†å‘€', 'è®¸è¯ºæ°¸è¿œæ»´ç¥!', 'ä¸€åŠ¨ä¸åŠ¨ä¼¼ç‹å…«?', 'è®¸è¯ºçœŸçš„ä¼šç©å—', 'æ— äº†', 'qgå…¨å‘˜éƒ½å¾ˆå¥½', 'è¿™é»„å¿ æ‰“äººæ‰“å¾—ç¬‘æ­»æˆ‘äº†', 'å¾ˆä¸é”™666å•Š', 'é»„å¿ ç ´æ™“äº†å•Š', 'æŒ‰æ—©äº†', 'æ€»æ˜¯è‡ªå·±æ–­èŠ‚å¥', 'æˆ‘è¦å¾—ä¸€å„¿', 'æ¯’å¥¶', 'ä¸¤é˜Ÿå·®è·å¤ªå¤§äº†', 'å¼€äº†è‡ªåŠ¨æ”»å‡»', 'é£å“¥ç‰›é€¼', 'è¾“äº†å•Š', 'å¤ªéš¾äº†å¤ªéš¾äº†', 'å¼ é£ä»¥ä¸ºç‹‚é“æœ€åé‚£ä¸€ä¸‹èƒ½æ‰“æ­»é»„å¿ ,æ‰€ä»¥å¤§å¼€æ™šäº†', 'é»„å¿ æ²¡äº†...', 'æ‰€ä»¥å°±æ˜¯è¯´æ˜¯åˆ¤æ–­å¤±è¯¯å˜›', 'ä¸å¥½æ‰“å•Š', 'æ„Ÿè§‰é»„å¿ cdå¥½å¤§', 'åˆšæ¥,é—®ä¸€ä¸‹å¥¶çš„è°', 'å•Šå•Šå•Š', 'æ¯’å¥¶é™ä¸´', 'qgæ˜¯ä¸æ˜¯æ²¡æ‰“è¿‡é¡ºé£å•Š', 'æˆ‘åäº†.å¬ä½ çš„å‹äº†qg', 'å“ˆå“ˆå“ˆ', 'æœ‰å†…é¬¼', 'æ¯’å¥¶', 'åˆºç—›æç™½?', 'æ¯’å¥¶å“ˆå“ˆå“ˆ', 'çº¿ä¹Ÿå·®,é¾™ä¹Ÿæ²¡,æ‰“æ¯›', 'qgæ²¡äº†', 'é»„å¿ ç»æµèµ·æ¥äº†', 'è¾…åŠ©ä¸è¡Œ', 'ä¸ä¼šè¢«é›¶å°å§', 'æ— äº†å‘€', 'è¿˜å¥½æˆ‘å‹çš„ag', 'è·Ÿæˆ‘å¿µ:qgè¿™æŠŠä¸å¥½æ‰“', 'æ¯’å¥¶', 'åˆ«å¸¦èŠ‚å¥', 'æ‰“æ¯›çº¿', 'qga', 'å”‰', 'ä½ å‡ºé’±,äººæœºagå…ˆä¸‹æ‰‹@aè–„è·ç³–13248æˆ‘å°±ä¸æ‡‚ä½ ä»¬ä¸ºä»€', 'â¤â¤â¤', 'å•Šå•Šå•Š', 'qgæ˜¯çœŸçš„èœå•Š', 'ä½ ä»¥ä¸º?  ä½ ç‰›é€¼ä½ ä¸Š?', 'åˆ«å–·äº†åˆ«å–·äº†', 'ä¸çœ‹äº†', 'giaoä¹‹å‰åœ¨ç»ƒæç™½', 'ä¸€åŠ¨ä¸åŠ¨ä¼¼ç‹å…«', 'åˆ‡ä¸åˆ°å¤ªéš¾äº†', 'å¸¦èŠ‚å¥è¿˜æœ‰ç†äº†?', 'æˆ‘åˆºç—›ä¹Ÿå¯ä»¥', 'æ— äº†', 'åè£”èƒ½ç«™æ’¸é»„å¿ ', 'å¯æƒœçœ‹ä¸åˆ°åŸºå°¼äº†', 'ä¸ºå•¥ç»™ç‰›æ‹¿å•å¸ƒå•Šé†‰äº†', 'è¦é›¶å°äº†', 'æŒ‡æŒ¥æ²¡æ€è·¯', 'å¹´å°‘è½¬èº«æ‹¿è“', 'æœ‰é“ç†å‘€', 'ç‹æ˜­å›æ‰“é»„å¿ å¾ˆå¥½æ‰“å•Š', 'å›½æœæ‰é¹Š', 'æ— äººèƒ½è¿‘èº«', 'è¾“äº†å•Š', 'åˆ«tmå¸¦èŠ‚å¥', 'qgåŠ æ²¹', 'æ€‚  çƒ¦æ­»äº†', 'æ— äº†æ— äº†', 'èœé€¼æ‰£é¸¡ğŸ”', 'ä½ å’‹è¿™ä¹ˆé€—ä¹å‘¢', 'ä¹°ä¸ªçº¯å‡€è‹ç©¹', 'é»›æ‰“æ‰“çš„èµ¢æç¬‘', 'åˆæ— äº†', 'çœŸ:æ¯’å¥¶', 'é»„å¿ ç»æµå¾ˆé«˜', 'è¯·é—®å“ªä¸ªå°„æ‰‹ç°åœ¨ä¸å˜æ€', 'å¸¦è®¸è¯ºèŠ‚å¥çš„æ˜¯æƒ³ä¸ŠéŸ­é»„ğŸ?', 'æ¯’å¥¶æ˜¯ä¸æ˜¯', 'å–·å­åˆæ¥äº†', 'å®Œäº†', 'boå‡ ', 'å“ˆå“ˆå“ˆ', 'ç ´äº§äº†', 'ä¸¤ç‚®è½°æ­»ä¸€ä¸ªcğŸ˜‚', 'qgä¸è¡Œ,æ°”æ­»äº†', 'è€å…µä¸è€', 'åˆºç—›æç™½?', 'muaï½', 'hurtåŠ æ²¹!å¹²ä»–!', 'æ¢¦å¥‡å¯ä»¥æ‰“é»„å¿ å—', 'åˆ«å¥¶äº†!', 'è®¸è¯ºè¾…åŠ©ä¸è¡Œ', 'èµ·æ¥å°±æ˜¯é»„ä¸‰ç‚®', 'æˆ‘æ„Ÿè§‰æ˜¯ç‹‚é“çš„é—®é¢˜', 'è¿˜å¥½æˆ‘å‹çš„ag', 'å¥½ç´§å¼ ', 'ä¸Šæ°æ°å§', 'ä¸€ç›´éƒ½è®¤ä¸ºè®¸è¯ºè¾…åŠ©ä¸€èˆ¬', 'ç ´æ™“äº†å¾ˆéš¾é¡¶', 'å¸é©¬æ‡¿è™æ€', 'å©‰å„¿å·è¢­å¯ä»¥', 'é»„å¿ ç»æµå¯ä»¥çš„', 'å¾ˆä¸é”™666å•Š', 'åç¾¿å·²ç»æ²¡é»„å¿ å‰å®³äº†', 'é»„å¿ æ¶ç‚®è·ç¦»å¤ªè¿œæ²¡æ³•å¤´åƒé”å®š', 'é»„å¿ ä½ è¢«å¥¶äº†,å¿«æ­»', '3æ¯”é›¶ç»“æŸå‘—?', 'è€å¤«å­åŠç€æ‰“', 'skr skr skr skr', 'æ€ä¹ˆæ„Ÿè§‰åˆè¦æ— äº†', 'é»„7æ³¡å“ˆå“ˆå“ˆ', 'é»„å¿ åæœŸè¶…çŒ›', 'â¤â¤â¤', 'å˜»å˜»', 'å–·è®¸è¯ºçš„æ˜¯æƒ³ä¸Šä¹æœˆè¿˜æ˜¯770?', 'å¤©å¤©å–·è®¸è¯º,é‚£ä¸Š770ä¹æœˆå§,çœ‹ä½ ä»¬æ˜¯è¾“æ˜¯èµ¢èµ–', 'giaoä¸è¡Œæ‰“ä¸äº†é‡æ ¸', 'ä¸ºä»€ä¹ˆqgç©é»„å¿ æ²¡æœ‰è¿™ç§æ„Ÿè§‰', 'ä¼šæ¢770å—', 'é¬¼è‹±é›„å“ˆå“ˆå“ˆ', 'qgå¥½èœå•Š', 'è¿˜åœ¨å¤§åº„,æŒ‰çº¯å‡€è‹ç©¹', 'æ…Œçš„ä¸€b', 'æ‰€ä»¥ç¬‘å½±ä»¥å‰å«æ±¤æ±¤å—', 'æ— äº†å‘€', 'æ¯’å¥¶', 'giaoä¹‹å‰åœ¨ç»ƒæç™½', 'é“¾æ¥qg', 'çœ‹å¾—æˆ‘å¿ƒè·³', 'äºŒè¥é•¿æŠŠæˆ‘çš„æ„å¤§åˆ©ç‚®æ‹¿æ¥', 'æ²Ÿé€šé—®é¢˜ åˆ«è¯´äº†', 'æˆ‘éƒ½è¯´äº†qgå¸®3:0å¸¦èµ°äº†', 'è¦è¢«é›¶å°äº†', 'è®¸è¯ºæ€»æ˜¯æ–­èŠ‚å¥å•Š', 'è¿™è°é¡¶å¾—ä½å•Š', 'qgæ€ä¹ˆæ²¡é‚£ä¹ˆå‰å®³äº†', 'é»„å¿ çš„å‘è‚²æ›²çº¿å¾ˆä¸çº¿æ€§', 'åˆèµ”äº†', 'ä¸ºå•¥ç»™ç‰›æ‹¿å•å¸ƒå•Šé†‰äº†', 'æ¯’å¥¶', 'æš´å›å‡»æ€agå“ˆå“ˆå“ˆ', 'åˆ«å¥¶äº†']
#
#
#avg,pos_avg,pos_pro,neg_avg,neg_pos=sentiment_fragment(test_list)
#print(avg,pos_avg,pos_pro,neg_avg,neg_pos)    


segmentor.release()    
    
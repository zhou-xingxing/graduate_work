# -*- coding: utf-8 -*-
"""
Created on Tue Mar 31 18:46:50 2020

@author: lenovo
"""

#åŸºäºè¯å…¸çš„æƒ…æ„Ÿåˆ†æ
import jieba
import os,time,csv
from pyltp import Segmentor
from data_cleaning import sim_replace,symbol_replace,emoji_replace,tradition2simple
from langconv import *
import pandas as pd


# åŠ è½½è‡ªå®šä¹‰è¯å…¸
jieba.load_userdict(r'../dict/self_dict.txt')


LTP_DATA_DIR = r'../ltp_data_v3.4.0/ltp_data_v3.4.0'  # ltpæ¨¡å‹ç›®å½•çš„è·¯å¾„
cws_model_path = os.path.join(LTP_DATA_DIR, 'cws.model')  # åˆ†è¯æ¨¡å‹è·¯å¾„ï¼Œæ¨¡å‹åç§°ä¸º`cws.model`
segmentor = Segmentor()  # åˆå§‹åŒ–å®ä¾‹
segmentor.load_with_lexicon(cws_model_path, r"../dict/self_dict.txt")  # åŠ è½½æ¨¡å‹ï¼Œç¬¬äºŒä¸ªå‚æ•°æ˜¯æ‚¨çš„å¤–éƒ¨è¯å…¸æ–‡ä»¶è·¯å¾„

pos_dict=pd.read_csv(r'../dict/self_positive_dict.txt',header=None)
pos_dict=pos_dict[0].tolist()

neg_dict=pd.read_csv(r'../dict/self_negative_dict.txt',header=None)
neg_dict=neg_dict[0].tolist()

not_dict=pd.read_csv(r'../dict/self_not.txt',header=None)
not_dict=not_dict[0].tolist()

with open("../dict/self_degree.txt",'r',encoding='utf-8') as f:    
    degree=eval(f.read()) #æŠŠå­—å…¸è½¬åŒ–ä¸ºstr 

degree_most=degree['most']
degree_more=degree['more']
degree_less=degree['less']
degree_least=degree['least']

print('æ­£é¢æƒ…æ„Ÿè¯:',len(pos_dict))
print('è´Ÿé¢æƒ…æ„Ÿè¯:',len(neg_dict))
print('å¦å®šè¯:',len(not_dict))
print('ç¨‹åº¦å‰¯è¯:',len(degree_most),len(degree_more),len(degree_less),len(degree_least))

with open(r"../dict/dyemot.txt", 'r')as f:
    emot_dict = eval(f.read())
#æ•°æ®æ¸…æ´—
def danmu_clean(sentence):
    
        
    sentence=symbol_replace(sentence)
    sentence=tradition2simple(sentence)
    sentence=sim_replace(sentence)
    sentence=emoji_replace(sentence,emot_dict)
    
    return sentence


#test_str = "[emot:dy104][emot:dy111]â¤ï¸â¤â¤â¤ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€â¤ğŸ’©ğŸ’©ğŸ’©ğŸ’©ğŸ’©ğŸ’©ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰ğŸ‰"
#print(danmu_clean(test_str))

#jiebaåˆ†è¯
def jieba_word(sentence):
    seg_list = jieba.cut(sentence)
    seg_result = []
# å»å¤šä½™ç©ºæ ¼
    for i in seg_list:
        if i==' ':
            continue
        else:
            seg_result.append(i)
    
    return seg_result

#ltpåˆ†è¯
def ltp_word(sentence):
    seg_result = segmentor.segment(sentence)
    return list(seg_result)


#è®¡ç®—æƒ…æ„Ÿå¾—åˆ†    
def sentence_score(seg_result):
    pos_score=0
    neg_score=0
    
    for i in range(0,len(seg_result)):        
        if seg_result[i] in pos_dict:
#            print('pos:',seg_result[i])
            tmp=1
#            å‘å‰æŸ¥1-2ä¸ªè¯
            for j in [1,2]:
                if i-j<0:
                    break
#                æœ‰æ ‡ç‚¹è¯´æ˜å‰åæ— è”ç³»ï¼Œæå‰ç»“æŸ
                if seg_result[i-j]==',' or seg_result[i-j]=='.':
                    break
                else:
                    if seg_result[i-j] in not_dict:
                        tmp=tmp*-1
                        continue
                    elif seg_result[i-j] in degree_most:
                        tmp=tmp*1.75
                        continue
                    elif seg_result[i-j] in degree_more:
                        tmp=tmp*1.5
                        continue
                    elif seg_result[i-j] in degree_less:
                        tmp=tmp*0.75
                        continue
                    elif seg_result[i-j] in degree_least:
                        tmp=tmp*0.5
                        continue
            pos_score+=tmp
        elif seg_result[i] in neg_dict:
#            print('neg:',seg_result[i])
            tmp=1
#            å‘å‰æŸ¥1-2ä¸ªè¯
            for j in [1,2]:
                if i-j<0:
                    break
                if seg_result[i-j]==',' or seg_result[i-j]=='.':
                    break
                else:
                    if seg_result[i-j] in not_dict:
#                        è´Ÿé¢è¯è¢«å¦å®šè¯ä¿®é¥°è§†ä¸ºæ— æƒ…æ„Ÿæˆ–ç•¥å¾®æ­£å‘
                        tmp=tmp*0
                        continue
                    elif seg_result[i-j] in degree_most:
                        tmp=tmp*1.75
                        continue
                    elif seg_result[i-j] in degree_more:
                        tmp=tmp*1.5
                        continue
                    elif seg_result[i-j] in degree_less:
                        tmp=tmp*0.75
                        continue
                    elif seg_result[i-j] in degree_least:
                        tmp=tmp*0.5
                        continue
            neg_score+=tmp
    
    score=pos_score-neg_score
#    print('score',score)
#    å¦‚æœå¥å­æœ€åæœ‰å¹å·
    if  seg_result[-1]=='!':
        score*=1.5
    return score    
                           
                        
#è¾“å‡ºå•æ¡å¼¹å¹•æƒ…æ„Ÿåˆ†æç»“æœ                        
def sentiment_result(sentence):                

#    åªæœ‰åœ¨æµ‹è¯•å•æ¡å¼¹å¹•æ—¶æ‰éœ€è¦æ¸…æ´—
#    sentence=danmu_clean(sentence)
#    ç‰¹æ®Šå¤„ç†ä¸¤ç§æƒ…å†µ
    if sentence=='???':
#        print('è´Ÿé¢')
        jieba_res=-1
        ltp_res=-1
#        return (jieba_res,ltp_res)  
        return jieba_res
    if sentence=='!!!':
#        print('æ­£é¢')
        jieba_res=1
        ltp_res=1
#        return (jieba_res,ltp_res)  
        return jieba_res
    if len(sentence)==0 or sentence==',' or sentence=='.':
#        print('ä¸­æ€§')
        jieba_res=0
        ltp_res=0
#        return (jieba_res,ltp_res) 
        return jieba_res
    
    
    jieba_list=jieba_word(sentence)
#    ltp_list=ltp_word(sentence)
#    
#    print('jieba_list:',jieba_list)
#    print('ltp_list:',ltp_list)
#    
    sentiment_jieba=sentence_score(jieba_list)
#    sentiment_ltp=sentence_score(ltp_list)
    
#    if sentiment_jieba>0:
#        print('jieba:','socre',sentiment_jieba,'class','æ­£é¢')
#    elif sentiment_jieba<0:
#        print('jieba:','socre',sentiment_jieba,'class','è´Ÿé¢')
#    else:
#        print('jieba:','socre',sentiment_jieba,'class','ä¸­æ€§')
#        
#    if sentiment_ltp>0:
#        print('ltp:','socre',sentiment_ltp,'class','æ­£é¢')
#    elif sentiment_ltp<0:
#        print('ltp:','socre',sentiment_ltp,'class','è´Ÿé¢')
#    else:
#        print('ltp:','socre',sentiment_ltp,'class','ä¸­æ€§')    
    
    if sentiment_jieba>0:
        jieba_res=1
    elif sentiment_jieba<0:
        jieba_res=-1
    else:
        jieba_res=0
        
#    if sentiment_ltp>0:
#        ltp_res=1
#    elif sentiment_ltp<0:
#        ltp_res=-1
#    else:
#        ltp_res=0
    
#    return (jieba_res,ltp_res)    
    return sentiment_jieba

#æŒ‰æ—¶é—´æ®µåˆ¤æ–­æƒ…æ„Ÿ
def sentiment_fragment(danmu_list):
    sentiment_score_list=[]
    sentiment_pos_score=[]
    sentiment_neg_score=[]
    for i in danmu_list:
        score=sentiment_result(i)
        sentiment_score_list.append(score)
        if score>0:
            sentiment_pos_score.append(score)
        if score<0:
            sentiment_neg_score.append(score)
    num=len(sentiment_score_list)        
    avg=sum(sentiment_score_list)/num
#è¿”å›æƒ…æ„Ÿå€¼ç´¯ç§¯å’Œã€å¹³å‡å€¼ã€æ­£å‘å’Œã€è´Ÿå‘å’Œ
#    return (sum(sentiment_score_list),avg,sum(sentiment_pos_score),sum(sentiment_neg_score))
#è¿”å›æƒ…æ„Ÿå‡å€¼ã€æ­£é¢æƒ…æ„Ÿå‡å€¼ã€æ­£é¢å¼¹å¹•æ¯”ã€è´Ÿé¢æƒ…æ„Ÿå‡å€¼ã€è´Ÿé¢å¼¹å¹•æ¯”
    return  (avg,sum(sentiment_pos_score)/num,len(sentiment_pos_score)/num,sum(sentiment_neg_score)/num,len(sentiment_neg_score)/num)  



#â¤ï¸
#â¤ è¿™ä¸¤ç§çº¢å¿ƒä¸ä¸€æ ·   
#sentence="åˆ«éª‚äº† ä¸è¦è„¸ ç»™ä½ è„¸äº† åˆ«ç»™è„¸ä¸è¦è„¸"
#i=sentiment_result(sentence)
#print(i)
#    
#æµ‹è¯•å¼¹å¹•
def test_danmu():    
    test_data=pd.read_csv(r'../data/test300_result_verify.csv')
    print('æµ‹è¯•æ•°é‡ï¼š',len(test_data))
    jieba_flag=[]
    ltp_flag=[]
    start_time=time.clock()
    for index,row in test_data.iterrows():
        danmu=str(row['danmu'])
        jieba_res,ltp_res=sentiment_result(danmu)
    #    print(jieba_res,ltp_res)
        jieba_flag.append(jieba_res)
        ltp_flag.append(ltp_res)
    end_time=time.clock()
    print('æµ‹è¯•ç”¨æ—¶ï¼š',end_time-start_time)
    test_data['jieba']=jieba_flag
    test_data['ltp']=ltp_flag
    test_data.to_csv(r'../data/new_test300_result_verify.csv',index=None)
    
#test_danmu()    
#
#æµ‹è¯•æ—¶é—´æ®µå¼¹å¹•
def test_danmu_frag():
#    è¿è¡Œ36ç§’
    data=pd.read_csv(r'../code/frag_cleaned_test_room911_20000.csv')
    time_group=data.groupby('fragment')    
    time_frag=[]
#    score_frag=[]
    avg_frag=[]
    pos_avg_frag=[]
    pos_pro_frag=[]
#    pos_frag=[]
#    neg_frag=[]
    start_time=time.clock()
    for gn,gl in time_group:
#        ä»¥æ¯ç»„ç¬¬ä¸€æ¡å¼¹å¹•æ—¶é—´ä¸ºåæ ‡å€¼
        time_frag.append(gl['time'].tolist()[0])
        avg,pos_avg,pos_pro=sentiment_fragment(gl['content'].tolist())
        
        avg_frag.append(avg)
        pos_avg_frag.append(pos_avg)
        pos_pro_frag.append(pos_pro)
    end_time=time.clock()
    print('æµ‹è¯•ç”¨æ—¶ï¼š',end_time-start_time)
    dic={'time_frag':time_frag,'avg_score':avg_frag,'pos_avg':pos_avg_frag,'pos_proportion':pos_pro_frag}
    senti_frag=pd.DataFrame(dic)
    senti_frag.to_csv(r'../code/new2_senti_frag_cleaned_test_room911_20000.csv',index=None)

#test_danmu_frag()

#ä¸ºæ—¶é—´æ®µåŠ ç‰¹å¾
def feature_danmu_frag():
#   380 170-180s
    data=pd.read_csv(r'../data/room911/final_room911danmu0206.csv') 
    avg_ls=[]
    pos_avg_ls=[]
    pos_prop_ls=[]
    neg_avg_ls=[]
    neg_prop_ls=[]
    start_time=time.clock()
    for index,row in data.iterrows():
#        print(row['danmu'],type(row['danmu']))
        avg,pos_avg,pos_prop,neg_avg,neg_prop=sentiment_fragment(eval(row['danmu']))
        
        avg_ls.append(avg)
        pos_avg_ls.append(pos_avg)
        pos_prop_ls.append(pos_prop)
        neg_avg_ls.append(neg_avg)
        neg_prop_ls.append(neg_prop)
    
    end_time=time.clock()
    print('æµ‹è¯•ç”¨æ—¶ï¼š',end_time-start_time)
    data['avg_score']=avg_ls
    data['pos_avg_score']=pos_avg_ls
    data['pos_proportion']=pos_prop_ls
    data['neg_avg_score']=neg_avg_ls
    data['neg_proportion']=neg_prop_ls
    
    data.to_csv(r'../data/room911/feature_final_room911danmu0206.csv',index=None)
    
    
    
        
#feature_danmu_frag()

#test_list=['ä¸å–œæ¬¢å…ƒæ­Œ,æ²¡æœ‰è§‚èµæ€§', 'ä¸»æ’­æ˜¯çœŸçš„é¡¶', 'éªšç™½æœ‰ä¸ªå‰å°¼æ–¯500è¿èƒœçš„', 'ä¸€ä¸ªäººçš„é€†é£', 'ä¸»æ’­æœ‰ç‚¹ä¸œè¥¿å“ˆ', 'å“ˆå–½', 'ä¸€ä¸ªä¸€æŠ€èƒ½,ä½ å°±æ²¡äº†', 'æ‹”ä¸æ‰é«˜åœ°ä½ ä»¬10åˆ†é’Ÿåå´©äº†', 'skr skr skr skr', 'æ˜¨å¤©æ€ä¹ˆæ²¡æœ‰æ’­å‘€', 'ç™½å“¥ä¹°ä¸ªå˜å£°å™¨å¼€éº¦å§', 'å›´ç»•ä»–æ‰“æ˜¯å› ä¸ºèŒèŠ½ å‚»å§', 'å™—', 'kk', 'å“ˆå“ˆå“ˆ', 'è¿™è°é¡¶å¾—ä½å•Š', 'å¹²å¾—æ¼‚äº®', '@aç—…æ€ææ€–ï¼šç™½å“¥ä¹°ä¸ªå˜å£°å™¨å¼€éº¦å§ å°±ä½ æ', '+++-----+---------------------', 'å“ˆå“ˆå“ˆ', 'é£˜äº†å•Š', 'ä½ è¯´è¯å°å£°ç‚¹å¬ä¸è§é˜Ÿå‹', 'ä½ ä»¬æ²¡å°„æ‰‹è¿˜æ•¢æ‰“åæœŸ?', '666', 'åæœŸæ‰“ä¸äº†', 'â¤â¤â¤', 'ä¸»æ’­æ˜¯çœŸçš„é¡¶', 'åæœŸèŒèŠ½æ— æ•Œäº†', 'å…ƒæ­Œè¿˜æ²¡è§‚èµæ€§?', '1433223', 'è¿™è°é¡¶å¾—ä½å•Š', 'è¿™ä¸€å¥—?', '666', 'å¾ˆä¸é”™666å•Š', 'skr skr skr skr', 'ä½ çœŸæ˜¯ä¸ªå˜è„¸æ¯”ç¿»ä¹¦è¿˜å¿«çš„ç”·äºº', 'è¢«è¿½ç€æ‰“ğŸ˜‚ğŸ˜‚ğŸ˜‚', 'çœŸå‰å®³', 'æºå“¥å¤ªé…·äº†', 'å¤ªæäº†', '666 99999999996699966996696696996996996969969699969966699999999666 666', 'æ€ä¹ˆåˆç©å…ƒæ­Œ', '666', 'ä¼šä¸ªå±', 'å¤ªéš¾äº†å¤ªéš¾äº†', 'ä¸»æ’­ä¸è¦é€—', 'ç™½å“¥å¿ƒæ€å´©äº†å“ˆå“ˆå“ˆ', 'ä¸€ä¸ªäººçš„é€†é£', 'â¤â¤â¤', '666', 'â¤â¤â¤', 'æ', 'ä½ æ˜¯çœŸçš„ç§€', 'è¿™æ˜¯ç™½å“¥ç©çš„æ', '233', 'ä»–ä»¬æ°¸è¿œä¸çŸ¥é“å…ƒæ­Œæ˜¯éªšç™½', 'ä½ æœ‰æœ¬äº‹å•æ€ä»–å‘€', '666', 'ç™½å¦¹', 'â¤â¤â¤', 'æ€ä¹ˆåˆæ˜¯å…ƒå“¥', 'çœŸå‰å®³', 'å¯¹é¢æç™½é€çš„', 'ğŸ˜“ğŸ˜“ğŸ˜“', 'çœ‹çœ‹ä¸“ä¸šæºå“¥çœŸç§€', 'çœŸå‰å®³', 'å˜å£°å™¨å¤šå¥½', '[å–µå–µ][å–µå–µ][å–µå–µ][å–µå–µ]', 'é¦™è•‰å‘³?è¿˜æ˜¯è‰è“å‘³?', 'ç™½å¦¹ä½ å” äº†', 'ç™½å“¥å¿ƒæ€å´©äº†å“ˆå“ˆå“ˆ', 'å“ˆå“ˆå“ˆ', '233', 'è¢«è¿½ç€æ‰“ğŸ˜‚ğŸ˜‚ğŸ˜‚', 'çœŸå‰å®³', 'jszrediyi', '666', 'éªšç™½ç”³è¯·äº¤æµ', '------++++', '233', 'èŒå¨ƒåæœŸè¾“å‡ºçˆ†ç‚¸ğŸ˜„ğŸ˜„ğŸ˜„', 'ä»Šå¤©åˆšå­¦ä¼šäº†å©‰å„¿èµ·é£.å¥½å¼€å¿ƒå¾ˆå¼€å¿ƒ.', 'å—¯å—¯?', '666', 'ä»–ä»¬æ°¸è¿œä¸ä¼šçŸ¥é“å…ƒæ­Œæ˜¯éªšç™½', '666', 'ä½ çœ‹çœ‹ä½ æˆ˜ç»©,ä½ ç©ä¸ªä»€ä¹ˆä¸œè¥¿', 'è¯ç“¶a', 'äºŒå¨ƒæ˜¯?', '@aäº‘1æ¥ä¹Ÿï¼šä¸å–œæ¬¢å…ƒæ­Œ,æ²¡æœ‰è§‚èµæ€§', 'ğŸ˜“ğŸ˜“ğŸ˜“', 'å¥½åƒæ˜¯djie', 'å¼±åŒ–æ‰“ä¸åŠ¨', 'è¶…å–œæ¬¢å…ƒæ­Œè¿™ä¸ªè‹±é›„', 'å‘µå‘µ', 'å°±å–œæ¬¢è¿™æ ·çš„ä½ .', 'ç™½å“¥å¿ƒæ€å´©äº†å“ˆå“ˆå“ˆ', 'å” ', 'å†ä¸ªé¬¼çš„è§', 'å¼±åŒ–', '???', 'ä½ åˆé£˜äº†', 'åº„å‘¨å¼±åŒ–', 'ä»–æ²¡è¢«æ•™è‚²è¿‡', 'ç¬‘æ­»æˆ‘äº†å“ˆå“ˆå“ˆ', 'è¿™è°é¡¶å¾—ä½å•Š', 'å¼€éº¦', 'ä½•æ­¢ä¸€ç‚¹', 'åæœŸä½ ä»¬ä¸¤æ³•å¸ˆï¼šå¹²å°†,æä¿¡,ä¸å¯èƒ½æ‰“ä¸è¿‡', 'ç«èˆçœŸç§€', 'å¼±åŒ–å•Š', 'å¤ªéš¾äº†å¤ªéš¾äº†', 'å“ˆå“ˆå“ˆ', 'å…­å…­å…­', 'è¢«è¿½ç€æ‰“ğŸ˜‚ğŸ˜‚ğŸ˜‚', '!!!', 'ç¡®å®å†è§', 'å‘µå‘µ', 'çjbä¹±å¼€', 'ç¬‘æ­»æˆ‘äº†å“ˆå“ˆå“ˆ', 'æ˜¯ä½ å¤ªç§€', 'è®²é“ç†,ä½ å…ƒæ­Œä¹Ÿå°±æ˜Ÿè€€æ°´å¹³', 'å¼€éº¦', 'ä¸€ç‚¹ç‚¹', 'å“ˆå“ˆå“ˆ', 'å¼€å±€ä½ å…­ç¥å°±èµ¢å®šäº†', 'ä½ æŠ€èƒ½æ­ªäº†', 'å†è§', 'ç™½å“¥å¿ƒæ€å´©äº†å“ˆå“ˆå“ˆ', 'å†è§,é˜Ÿå‹', 'å¾ˆå¤§çš„é—®é¢˜', 'å°±å–œæ¬¢è¿™æ ·çš„ä½ .', 'å“ˆå“ˆå“ˆ', 'ç‰›çš®', 'å¼±åŒ–', 'ğŸˆ¶å¼±åŒ–', 'ä½ lowäº†', 'è¢«è¿½ç€æ‰“ğŸ˜‚ğŸ˜‚ğŸ˜‚', 'è¢«è¿½ç€æ‰“ğŸ˜‚ğŸ˜‚ğŸ˜‚', '33-', 'ä½ çœŸçš„ç§€', 'å“ˆå“ˆå“ˆ', 'å“ˆå“ˆå“ˆ', 'å“¥,æˆ‘åˆæ¥äº†', 'åŠ æ²¹', 'è¢«è¿½ç€æ‰“ğŸ˜‚ğŸ˜‚ğŸ˜‚', 'å“ˆå“ˆå“ˆ èˆ’æœäº†', 'è‹¥å,ç°åœ¨å‰ªä¸Šè´¼å‰å®³', 'æ··å­', 'ä¸€ç‚¹ç‚¹å—', 'â¤â¤â¤', 'è™šå¼±äº†', 'åˆ‡ä¸åˆ°åæ’', 'ä½ æ²¡ç‚¹ç”¨', 'å…ƒå“¥çš„æŠ€èƒ½ä¸å¤ªå¥½çœ‹', 'è…Šé¸¡', 'å¼±åŒ–å¤ªå¼ºäº†', 'ä¸æœ‰å¼±åŒ–', 'å›¢ç­å‘åŠ¨æœº', 'å¿ƒç†æˆ˜', 'é…åˆä¸é»˜å¥‘', 'å¼±åŒ–', 'ä¸»æ’­æœ‰ç‚¹ä¸œè¥¿å“ˆ', 'æ¢¦é£çš„è¿èƒœæ˜¯å•¥æ„æ€', 'å¼±åŒ–äº†', 'æ‹½çŠ¯æ³•å—,æœ‰å“ªæ¡æ³•å¾‹è§„å®šäººä¸èƒ½æ‹½çš„', '???', 'ç™½å“¥å¿ƒæ€å´©äº†å“ˆå“ˆå“ˆ', 'skr skr skr skr', 'å¼±åŒ–', 'å¼€å§‹æŠ±å¤§è…¿', 'llæ²¡äº‹', 'éš¾å—', 'å“ˆå“ˆå“ˆ', 'å°±å–œæ¬¢è¿™æ ·çš„ä½ .', 'äº¿ç‚¹ç‚¹']
#
#
#avg,pos_avg,pos_pro,neg_avg,neg_pos=sentiment_fragment(test_list)
#print(avg,pos_avg,pos_pro,neg_avg,neg_pos)    


segmentor.release()    
    